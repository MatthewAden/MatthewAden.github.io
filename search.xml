<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>逻辑回归</title>
      <link href="/2022/02/10/2.10%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"/>
      <url>/2022/02/10/2.10%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/</url>
      
        <content type="html"><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>逻辑回归是一种<strong>分类</strong>模型，由条件概率分布P(Y|X)表示,形式为<strong>参数化</strong>(待会参数要算出)的逻辑斯蒂分布，它与最大熵模型一样一样都是对数线性模型，输出某个类的对数几率与输入实例的线性函数</p><h2 id="推导"><a href="#推导" class="headerlink" title="推导"></a>推导</h2><p><img src="https://cdn.jsdelivr.net/gh/MatthewAden/blog.img/image-20220210231327561.png" alt="推导过程" style="zoom: 25%;" /></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
          <category> 李航统计学习方法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>决策树(2)</title>
      <link href="/2022/02/07/2.7%E5%86%B3%E7%AD%96%E6%A0%91(2)/"/>
      <url>/2022/02/07/2.7%E5%86%B3%E7%AD%96%E6%A0%91(2)/</url>
      
        <content type="html"><![CDATA[<h2 id="决策树算法-CART算法"><a href="#决策树算法-CART算法" class="headerlink" title="决策树算法(CART算法)"></a>决策树算法(CART算法)</h2><p>对于C4.5算法，我们也提到了它的不足，比如模型是用较为复杂的熵来度量，使用了相对较为复杂的多叉树，只能处理分类不能处理回归等。对于这些问题， CART算法大部分做了改进。CART算法也就是我们下面的重点了。由于CART算法可以做回归，也可以做分类，我们分别加以介绍，先从CART分类树算法开始，重点比较和C4.5算法的不同点。接着介绍CART回归树算法，重点介绍和CART分类树的不同点。然后我们讨论CART树的建树算法和剪枝算法，最后总结决策树算法的优缺点。</p><h3 id="1-CART分类树算法的最优特征选择方法"><a href="#1-CART分类树算法的最优特征选择方法" class="headerlink" title="1.CART分类树算法的最优特征选择方法"></a>1.CART分类树算法的最优特征选择方法</h3><p>在<strong>ID3算法</strong>中我们使用了<strong>信息增益</strong>来选择特征，信息增益大的优先选择。在<strong>C4.5算法</strong>中，采用了<strong>信息增益比</strong>来选择特征，以减少信息增益容易选择特征值多的特征的问题。但是无论是ID3还是C4.5,都是基于信息论的熵模型的，这里面会涉及大量的对数运算。能不能简化模型同时也不至于完全丢失熵模型的优点呢？有！<strong>CART分类树算法使用基尼系数</strong>来代替信息增益比，基尼系数代表了模型的不纯度，基尼系数越小，则不纯度越低，特征越好。这和信息增益(比)是相反的。</p><h3 id="2-CART分类树算法对于连续特征和离散特征处理的改进"><a href="#2-CART分类树算法对于连续特征和离散特征处理的改进" class="headerlink" title="2. CART分类树算法对于连续特征和离散特征处理的改进"></a>2. CART分类树算法对于连续特征和离散特征处理的改进</h3><p>  对于CART分类树连续值的处理问题，其思想和C4.5是相同的，都是将连续的特征离散化。唯一的区别在于在选择划分点时的度量方式不同，C4.5使用的是<strong>信息增益比</strong>，则CART分类树使用的是<strong>基尼系数</strong>。</p><p>  具体的思路如下，比如m个样本的连续特征A有m个，从小到大排列为a1,a2,…,am,则CART算法取相邻两样本值的平均数，一共取得m-1个划分点，其中第i个划分点Ti，对于这m-1个点，分别计算以该点作为二元分类点时的基尼系数。选择基尼系数最小的点作为该连续特征的二元离散分类点。比如取到的基尼系数最小的点为at,则小于at的值为类别1，大于at的值为类别2，这样我们就做到了连续特征的离散化。要注意的是，与ID3或者C4.5处理离散属性不同的是，如果当前节点为连续属性，则该属性后面还可以参与子节点的产生选择过程。</p><p>  对于CART分类树离散值的处理问题，采用的思路是不停的<strong>二分离散特征</strong>。回忆下ID3或者C4.5，如果某个特征A被选取建立决策树节点，如果它有A1,A2,A3三种类别，我们会在决策树上一下建立一个三叉的节点。这样导致<strong>决策树是多叉树</strong>。但是CART分类树使用的方法不同，他采用的是不停的二分，还是这个例子，CART分类树会考虑把A分成{A1}和{A2,A3}{A1}和{A2,A3}, {A2}和{A1,A3}{A2}和{A1,A3}, {A3}和{A1,A2}{A3}和{A1,A2}三种情况，找到基尼系数最小的组合，比如{A2}和{A1,A3}{A2}和{A1,A3},然后建立二叉树节点，一个节点是A2对应的样本，另一个节点是{A1,A3}对应的节点。同时，由于这次没有把特征A的取值完全分开，后面我们还有机会在子节点继续选择到特征A来划分A1和A3。这和ID3或者C4.5不同，在ID3或者C4.5的一棵子树中，离散特征只会参与一次节点的建立。</p><h3 id="3-CART回归树建立"><a href="#3-CART回归树建立" class="headerlink" title="3.CART回归树建立"></a><strong>3.CART回归树建立</strong></h3><p>CART回归树和CART分类树的建立算法大部分是类似的，所以这里我们只讨论CART回归树和CART分类树的建立算法不同的地方。</p><p>  首先，我们要明白，什么是回归树，什么是分类树。两者的区别在于样本输出，如果样本输出是离散值，那么这是一颗分类树。如果果样本输出是连续值，那么那么这是一颗回归树。</p><p>  除了概念的不同，CART回归树和CART分类树的建立和预测的区别主要有下面两点：</p><p><strong>1.连续值的处理方法不同</strong></p><p><strong>2.决策树建立后做预测的方式不同</strong></p><h3 id="4-CART算法的剪枝"><a href="#4-CART算法的剪枝" class="headerlink" title="4.CART算法的剪枝"></a>4.CART算法的剪枝</h3><p><img src="https://cdn.jsdelivr.net/gh/MatthewAden/blog.img/image-20220207124856003.png" alt="算法的剪枝"></p><h3 id="5-小结"><a href="#5-小结" class="headerlink" title="5.小结"></a>5.小结</h3><div class="table-container"><table><thead><tr><th style="text-align:center">算法</th><th style="text-align:center">支持模型</th><th style="text-align:center">树结构</th><th style="text-align:center">特征选择</th><th style="text-align:center">连续值处理</th><th style="text-align:center">缺失值处理</th><th style="text-align:center">剪枝</th></tr></thead><tbody><tr><td style="text-align:center">ID3</td><td style="text-align:center">分类</td><td style="text-align:center">多叉树</td><td style="text-align:center">信息增益</td><td style="text-align:center">不支持</td><td style="text-align:center">不支持</td><td style="text-align:center">不支持</td></tr><tr><td style="text-align:center">C4.5</td><td style="text-align:center">分类</td><td style="text-align:center">多叉树</td><td style="text-align:center">信息增益比</td><td style="text-align:center">支持</td><td style="text-align:center">支持</td><td style="text-align:center">支持</td></tr><tr><td style="text-align:center">CART</td><td style="text-align:center">分类、回归</td><td style="text-align:center">二叉树</td><td style="text-align:center">基尼系数、均方差</td><td style="text-align:center">支持</td><td style="text-align:center">支持</td><td style="text-align:center">支持</td></tr></tbody></table></div><p>　　　　</p><p>​                1）应该大家有注意到，无论是ID3, C4.5还是CART,在做特征选择的时候都是选择最优的一个特征来做分类决策，但是大多数，分类决策不应该是由某一个特征决定的，而是应该由一组特征决定的。这样决策得到的决策树更加准确。这个决策树叫做多变量决策树(multi-variate decision tree)。在选择最优特征的时候，多变量决策树不是选择某一个最优特征，而是选择最优的一个特征线性组合来做决策。这个算法的代表是OC1</p><p>　　　　2）如果样本发生一点点的改动，就会导致树结构的剧烈改变。这个可以通过集成学习里面的随机森林之类的方法解决。　　　</p><p>首先我们看看决策树算法的优点：</p><p>　　　　1）简单直观，生成的决策树很直观。</p><p>　　　　2）基本不需要预处理，不需要提前归一化，处理缺失值。</p><p>　　　　3）使用决策树预测的代价是O(log2m)O(log2m)。 m为样本数。</p><p>　　　　4）既可以处理离散值也可以处理连续值。很多算法只是专注于离散值或者连续值。</p><p>　　　　5）可以处理多维度输出的分类问题。</p><p>　　　　6）相比于神经网络之类的黑盒分类模型，决策树在逻辑上可以得到很好的解释</p><p>　　　　7）可以交叉验证的剪枝来选择模型，从而提高泛化能力。</p><p>　　　　8） 对于异常点的容错能力好，健壮性高。</p><p>我们再看看决策树算法的缺点:</p><p>　　　　1）决策树算法非常容易过拟合，导致泛化能力不强。可以通过设置节点最少样本数量和限制决策树深度来改进。</p><p>　　　　2）决策树会因为样本发生一点点的改动，就会导致树结构的剧烈改变。这个可以通过集成学习之类的方法解决。</p><p>　　　　3）寻找最优的决策树是一个NP难的问题，我们一般是通过启发式方法，容易陷入局部最优。可以通过集成学习之类的方法来改善。</p><p>　　　　4）有些比较复杂的关系，决策树很难学习，比如异或。这个就没有办法了，一般这种关系可以换神经网络分类方法来解决。</p><p>　　　　5）如果某些特征的样本比例过大，生成决策树容易偏向于这些特征。这个可以通过调节样本权重来改善。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
          <category> 李航统计学习方法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>决策树(1)</title>
      <link href="/2022/02/05/2.5%E5%86%B3%E7%AD%96%E6%A0%91(1)/"/>
      <url>/2022/02/05/2.5%E5%86%B3%E7%AD%96%E6%A0%91(1)/</url>
      
        <content type="html"><![CDATA[<h2 id="决策树概述"><a href="#决策树概述" class="headerlink" title="决策树概述"></a>决策树概述</h2><ul><li><p>是一种用于<strong>分类</strong>和<strong>回归</strong>的方法</p></li><li><p>通常包含三个步骤：<strong>特征选择</strong>、<strong>决策树生成</strong>和<strong>决策树修剪</strong></p></li></ul><p>Q1.分类和回归的区别？</p><div class="table-container"><table><thead><tr><th style="text-align:center">属性</th><th style="text-align:center">分类</th><th style="text-align:center">回归</th></tr></thead><tbody><tr><td style="text-align:center">输出类型</td><td style="text-align:center">离散数据</td><td style="text-align:center">连续数据</td></tr><tr><td style="text-align:center">评估指标</td><td style="text-align:center">监督分类一般<strong>使用正确率</strong>作为指标</td><td style="text-align:center"><strong>决定系数R方</strong></td></tr></tbody></table></div><h2 id="决策树算法"><a href="#决策树算法" class="headerlink" title="决策树算法"></a>决策树算法</h2><ul><li>通常包括三种算法ID3，C4.5，CART，在<strong>sklearn中采用优化了的CART</strong>算法来作为决策树实现</li></ul><h3 id="1-ID3算法："><a href="#1-ID3算法：" class="headerlink" title="1.ID3算法："></a>1.<strong>ID3算法</strong>：</h3><p>  作为一个码农经常会不停的敲if, else if, else,其实就已经在用到决策树的思想了。有这么多条件，用哪个条件特征先做if，哪个条件特征后做if比较优呢？怎么准确的定量选择这个标准就是决策树机器学习算法的关键了。昆兰找到了用<strong>信息论中的熵</strong>来度量决策树的决策选择过程，这个算法叫做ID3。</p><p><strong>信息论中熵的概念：</strong>熵度量了事物的<strong>不确定性</strong>，越不确定的事物，它的熵就越大。具体的，随机变量X的熵的表达式如下：</p><script type="math/tex; mode=display">H\left( X \right) =-\underset{i=1}{\overset{n}{\varSigma}}p_i\log p_i</script><p>  其中n代表X的n种不同的离散取值。而$$<br>p_i</p><script type="math/tex; mode=display">代表了X取值为i的概率，log为以2或者e为底的对数。举个例子，比如X有2个可能的取值，而这两个取值各为1/2时X的熵最大，此时X具有最大的不确定性。值为。</script><p>H\left( X \right) =-\left( \frac{1}{2}\log \frac{1}{2}+\frac{1}{2}\log \frac{1}{2} \right) </p><script type="math/tex; mode=display">，如果一个值概率大于1/2，另一个值概率小于1/2，则不确定性减少，对应的熵也会减少。又可以得到条件熵的表达式H(X|Y)，条件熵类似于条件概率,它度量了我们的X在知道Y以后剩下的不确定性。表达式如下：</script><p>H\left( X|Y \right) =\underset{j=1}{\overset{n}{\varSigma}}p\left( y_j \right) H\left( X|y_j \right)</p><script type="math/tex; mode=display">  我们刚才提到H(X)度量了X的不确定性，条件熵H(X|Y)度量了我们在知道Y以后X剩下的不确定性，那么H(X)-H(X|Y)呢？从上面的描述大家可以看出，它度量了X在知道Y以后不确定性减少程度，这个度量在信息论中称为互信息，记为I(X,Y)。在决策树ID3算法中叫做信息增益。ID3算法就是用信息增益来判断当前节点应该用什么特征来构建决策树。**信息增益大，则越适合用来分类。**### 2.**算法步骤：**  上面提到ID3算法就是用信息增益大小来判断当前节点应该用什么特征来构建决策树，用计算出的信息增益最大的特征来建立决策树的当前节点。这里我们举一个信息增益计算的具体的例子。比如我们有15个样本D，输出为0或者1。其中有9个输出为1， 6个输出为0。 样本中有个特征A，取值为A1，A2和A3。在取值为A1的样本的输出中，有3个输出为1， 2个输出为0，取值为A2的样本输出中,2个输出为1,3个输出为0， 在取值为A3的样本中，4个输出为1，1个输出为0，样本D在特征下的条件熵为：</script><p>H\left( D|A \right) =\frac{5}{15}H\left( D1 \right) +\frac{5}{15}H\left( D2 \right) +\frac{5}{15}H\left( D3 \right)</p><p>$$</p><p>对应的信息增益为 I(D,A)=H(D)−H(D|A)=0.083I(D,A)=H(D)−H(D|A)=0.083　　　　　　　　　　　　</p><p><strong>下面我们看看具体算法过程大概是怎么样的。</strong></p><p>输入的是m个样本，样本输出集合为D，每个样本有n个离散特征，特征集合即为A，输出为决策树T。</p><p>算法的过程为：</p><p>　　　　1)初始化信息增益的阈值ϵ</p><p>　　　　2）判断样本是否为同一类输出DiDi，如果是则返回单节点树T。标记类别为Di</p><p>   　　　　3) 判断特征是否为空，如果是则返回单节点树T，标记类别为样本中输出类别D实例数最多的类别</p><p>　　　　4）计算A中的各个特征（一共n个）对输出D的信息增益，选择信息增益最大的特征Ag</p><p>   　　　　5) 如果AgAg的信息增益小于阈值ϵ，则返回单节点树T，标记类别为样本中输出类别D实例数最多的类别</p><p>　　　　6）否则，按特征Ag的不同取值Agi将对应的样本输出D分成不同的类别Di。每个类别产生一个子节点。对应特征值为Agi，返回增加了节点的数T</p><p>　　　　7）对于所有的子节点，令D=Di,A=A−{Ag}递归调用2-6步，得到子树Ti并返回</p><h3 id="3-算法缺陷"><a href="#3-算法缺陷" class="headerlink" title="3.算法缺陷"></a>3.算法缺陷</h3><p>  ID3算法虽然提出了新思路，但是还是有很多值得改进的地方。　　</p><p>   　　　　1. ID3没有考虑连续特征，比如长度，密度都是连续值，无法在ID3运用。这大大限制了ID3的用途。<br>   　　　　2. ID3采用信息增益大的特征优先建立决策树的节点。很快就被人发现，在相同条件下，取值比较多的特征比取值少的特征信息增大。比如一个变量有2个值，各为1/2，另一个变量为3个值，各为1/3，其实他们都是完全不确定的变量，但是取3个值的比取2个值的信息增益大。<br>   　　　　3. ID3算法对于缺失值的情况没有做考虑。</p><ol><li>没有考虑过拟合的问题。</li></ol><p>基于上述不足，对ID3算法做了改进，这就是C4.5算法</p><h3 id="4-算法改进-C4-5算法"><a href="#4-算法改进-C4-5算法" class="headerlink" title="4.算法改进(C4.5算法)"></a>4.算法改进(C4.5算法)</h3><p>  对于第一个问题，不能处理连续特征， C4.5的思路是将连续的特征离散化。比如m个样本的连续特征A有m个，从小到大排列为a1,a2,…,am,则C4.5取相邻两样本值的平均数，一共取得m-1个划分点，其中第i个划分点Ti表示Ti表示Ti=ai+ai+12Ti=ai+ai+12。对于这m-1个点，分别计算以该点作为二元分类点时的信息增益。选择信息增益最大的点作为该连续特征的二元离散分类点。比如取到的增益最大的点为atat,则小于atat的值为类别1，大于atat的值为类别2，这样我们就做到了连续特征的离散化。要注意的是，与离散属性不同的是，如果当前节点为连续属性，则该属性后面还可以参与子节点的产生选择过程。</p><p>  对于第二个问题，信息增益作为标准容易偏向于取值较多的特征的问题。我们引入一个信息增益比的变量IR(X,Y)IR(X,Y)，它是信息增益和特征熵的比值。</p><p>  对于第三个缺失值处理的问题，主要需要解决的是两个问题，一是在样本某些特征缺失的情况下选择划分的属性，二是选定了划分属性，对于在该属性上缺失特征的样本的处理。</p><p>  对于第一个子问题，对于某一个有缺失特征值的特征A。C4.5的思路是将数据分成两部分，对每个样本设置一个权重（初始可以都为1），然后划分数据，一部分是有特征值A的数据D1，另一部分是没有特征A的数据D2. 然后对于没有缺失特征A的数据集D1来和对应的A特征的各个特征值一起计算加权重后的信息增益比，最后乘上一个系数，这个系数是无特征A缺失的样本加权后所占加权总样本的比例。</p><p>  对于第二个子问题，可以将缺失特征的样本同时划分入所有的子节点，不过将该样本的权重按各个子节点样本的数量比例来分配。比如缺失特征A的样本a之前权重为1，特征A有3个特征值A1,A2,A3。 3个特征值对应的无缺失A特征的样本个数为2,3,4.则a同时划分入A1，A2，A3。对应权重调节为2/9,3/9, 4/9。</p><p>对于第4个问题，C4.5引入了正则化系数进行初步的剪枝。</p><p>除了上面的4点，C4.5和ID的思路区别不大。</p><p>　　　　</p><h3 id="5-决策树C4-5算法的不足与思考"><a href="#5-决策树C4-5算法的不足与思考" class="headerlink" title="5. 决策树C4.5算法的不足与思考"></a>5. 决策树C4.5算法的不足与思考</h3><p>C4.5虽然改进或者改善了ID3算法的几个主要的问题，仍然有优化的空间。</p><p>　　　　1.由于决策树算法非常容易过拟合，因此对于生成的决策树必须要进行剪枝。剪枝的算法有非常多，C4.5的剪枝方法有优化的空间。思路主要是两种，一种是预剪枝，即在生成决策树的时候就决定是否剪枝。另一个是后剪枝，即先生成决策树，再通过交叉验证来剪枝。后面在下篇讲CART树的时候我们会专门讲决策树的减枝思路，主要采用的是后剪枝加上交叉验证选择最合适的决策树。</p><p>　　　　2.C4.5生成的是多叉树，即一个父节点可以有多个节点。很多时候，在计算机中二叉树模型会比多叉树运算效率高。如果采用二叉树，可以提高效率。</p><p>　　　　3.C4.5只能用于分类，如果能将决策树用于回归的话可以扩大它的使用范围。</p><p>　　　　4.C4.5由于使用了熵模型，里面有大量的耗时的对数运算,如果是连续值还有大量的排序运算。如果能够加以模型简化可以减少运算强度但又不牺牲太多准确性的话，那就更好了。</p><p> 　这4个问题在CART树里面部分加以了改进。所以目前如果不考虑集成学习话，在普通的决策树算法里，CART算法算是比较优的算法了。<strong>scikit-learn的决策树使用的也是CART算法。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
          <category> 李航统计学习方法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>已安装某个包vscode无法调用</title>
      <link href="/2022/02/01/1.31/"/>
      <url>/2022/02/01/1.31/</url>
      
        <content type="html"><![CDATA[<h2 id="Q：安装了sklearn但在vscode中调包sklearn出现："><a href="#Q：安装了sklearn但在vscode中调包sklearn出现：" class="headerlink" title="Q：安装了sklearn但在vscode中调包sklearn出现："></a>Q：安装了sklearn但在vscode中调包sklearn出现：</h2><pre class="language-python" data-language="python"><code class="language-python">No module named &#39;sklearn&#39; </code></pre><p><strong>法一：</strong></p><pre class="language-python" data-language="python"><code class="language-python">python(your version here, example:3.9) -m pip install (package name here, example: scikit-learn)例：在vscode命令行输入：python -m pip install sklearn</code></pre><p><strong>法二：</strong></p><p>改变vscode的解释器：</p><p><img src="https://cdn.jsdelivr.net/gh/MatthewAden/blog.img/InkeduTools_1643769250398_LI.jpg" style="zoom:50%;" /></p>]]></content>
      
      
      <categories>
          
          <category> 编程中遇到的问题 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>朴素贝叶斯小结</title>
      <link href="/2022/01/30/1.30/"/>
      <url>/2022/01/30/1.30/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>   贝叶斯学派很古老，但是从诞生到一百年前一直不是主流。主流是频率学派。频率学派的权威皮尔逊和费歇尔都对贝叶斯学派不屑一顾，但是贝叶斯学派硬是凭借在现代特定领域的出色应用表现为自己赢得了半壁江山。</p><p>  贝叶斯学派的思想可以概括为先验概率+数据=后验概率。也就是说我们在实际问题中需要得到的后验概率，可以通过先验概率和数据一起综合得到。数据大家好理解，被频率学派攻击的是先验概率，一般来说先验概率就是我们对于数据所在领域的历史经验，但是这个经验常常难以量化或者模型化，于是贝叶斯学派大胆的假设先验分布的模型，比如正态分布，beta分布等。这个假设一般没有特定的依据，因此一直被频率学派认为很荒谬。虽然难以从严密的数学逻辑里推出贝叶斯学派的逻辑，但是在很多实际应用中，贝叶斯理论很好用，比如垃圾邮件分类，文本分类。</p><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>朴素贝叶斯是基于<strong>贝叶斯定理</strong>与<strong>特征条件独立假设</strong>的<strong>分类</strong>方法</p><ul><li>属于生成方法——-与<strong>判别方法</strong>直接学习出特征输出Y和特征X之间的关系,即学习<strong>决策函数Y=f(X)</strong>要么是<strong>条件分布P(Y|X)</strong>。朴素贝叶斯却是生成方法，也就是直接找出特征输出Y和特征X的<strong>联合分布P(X,Y)</strong>,<strong>P(X,Y)=P(X|Y)*P(Y</strong>),然后用<strong>P(Y|X)=P(X,Y)/P(X)</strong>得出。</li><li>特征条件独立假设是贝叶斯定理中的一个大胆假设，即假设输入中特征条件相互独立，优点是极大减少计算量，缺点是可能会造成预测的不准确性</li><li>分类的原则是依据贝叶斯定理求出的<strong>后验概率P(Y|X)</strong>，即选择<strong>后验概率最大</strong>的作为预测的类别结果</li><li></li></ul><h2 id="推断过程"><a href="#推断过程" class="headerlink" title="推断过程"></a>推断过程</h2><p>我们预测的类别C~result~是使P(Y=C~k~|X=X^(test)^)最大化的类别，数学表达式为：</p><script type="math/tex; mode=display">\begin{aligned}C_{\text {result }} &=\underbrace{\operatorname{argmax}}_{C_{k}} P\left(Y=C_{k} \mid X=X^{(\text {test })}\right) \\&=\underbrace{\operatorname{argmax}}_{C_{k}} P\left(X=X^{(\text {test })} \mid Y=C_{k}\right) P\left(Y=C_{k}\right) / P\left(X=X^{(\text {test })}\right)\end{aligned}</script><p>由于对于所有分类分母是一样的，加上独立性假设，则公式可简化为</p><script type="math/tex; mode=display">C_{\text {result }}=\underbrace{\operatorname{argmax}}_{C_{k}} P\left(Y=C_{k}\right) \prod_{j=1}^{n} P\left(X_{j}=X_{j}^{(t e s t)} \mid Y=C_{k}\right)</script><hr><p>某些时候，可能<strong>某些类别在样本中没有出现</strong>，这样可能导致P(X~j~=X^test)^|Y=C~k~)为0，这样会影响后验的估计，为了解决这种情况，我们引入了拉普拉斯平滑，即此时有：</p><script type="math/tex; mode=display">P_{\lambda}\left(Y=c_{k}\right)=\frac{\sum_{i=1}^{N} I\left(y_{i}=c_{k}\right)+\lambda}{N+K \lambda}</script><script type="math/tex; mode=display">P_{\lambda}\left(X^{(j)}=a_{j l} \mid Y=c_{k}\right)=\frac{\sum_{i=1}^{N} I\left(x_{i}^{(j)}=a_{j l}, y_{i}=c_{k}\right)+\lambda}{\sum_{i=1}^{N} I\left(y_{i}=c_{k}\right)+S_{j} \lambda}</script><p>其中λ为一个大于0的常数,常常取为1,<strong>K的取值与类别个数相同</strong>，<strong>S的取值与特征个数相同</strong>（<strong>注意区分特征个数与一个特征中可能有多个分量，比如天气属于一个特征，但天气包含下雨晴天等</strong>）</p><h2 id="例题"><a href="#例题" class="headerlink" title="例题"></a>例题</h2><p><img src="https://cdn.jsdelivr.net/gh/MatthewAden/blog.img/uTools_1643634908564.png" alt="例"></p><p><img src="https://cdn.jsdelivr.net/gh/MatthewAden/blog.img/image-20220131211410597.png" style="zoom: 25%;" /></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
          <category> 李航统计学习方法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>vscode调试带有scanf函数无法输入</title>
      <link href="/2022/01/26/1.26/"/>
      <url>/2022/01/26/1.26/</url>
      
        <content type="html"><![CDATA[<ul><li>断点应设在scanf下面的语句</li></ul><p><img src="https://cdn.jsdelivr.net/gh/MatthewAden/blog.img/image-20220126131757527.png" alt=""></p><ul><li>externaIConsole改为true</li></ul><p><img src="https://cdn.jsdelivr.net/gh/MatthewAden/blog.img/image-20220126132130359.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 编程中遇到的问题 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>统计学习方法第一章(1)</title>
      <link href="/2022/01/23/1.23/"/>
      <url>/2022/01/23/1.23/</url>
      
        <content type="html"><![CDATA[<h2 id="监督学习-Supervised"><a href="#监督学习-Supervised" class="headerlink" title="监督学习(Supervised)"></a>监督学习(Supervised)</h2><p>(<strong>目的是在于学习由输入到输出的映射，这一映射用模型来表示，学习的目的也就是找到最好的这样的模型</strong>)</p><p>1.输入空间、特征空间和输出空间</p><p>2.统计学习假设数据存在一定的统计规律，X,Y具有联合概率分布是监督学习的基本假设</p><p>3.假设空间(模型属于输入空间到输出空间的映射的集合)，这种模型可以是概率模型也可以是非概率模型，由条件概率分布或决策函数表示，随具体的学习方法而定</p><p>根据输入X与输出变量Y有不同的类型，对预测任务有不同的名称 </p><ul><li>均为连续变量的预测问题称为回归问题</li><li>输入为有限个离散的预测问题称为分类问题</li><li>均为变量序列的预测问题称为标注问题</li><li>监督学习利用训练集学习一个模型，表示为决策函数(即一个输入对应一个输出)或者是条件概率分布(一个输入对应输出的一个概率分布)，再用模型对测试样本集进行预测                                       </li></ul><h2 id="无监督学习-Unsupervised-Learning"><a href="#无监督学习-Unsupervised-Learning" class="headerlink" title="无监督学习(Unsupervised Learning)"></a>无监督学习(Unsupervised Learning)</h2><p>(<strong>是指从无标注数据中学习预测模型的机器学习问题，预测模型表示数据的类别、转换或概率。无监督学习的本质是学习数据中的统计规律或潜在结构,模型可实现对数据的聚类、降维或概率估计，无监督学习可以用于对已有数据的分析，也可以用于对未来数据的预测</strong>）</p><p><img src="https://cdn.jsdelivr.net/gh/MatthewAden/blog.img/image-20220123191852023.png" alt="无监督学习" style="zoom:50%;" /></p><h2 id="强化学习-Reinforcement-Learning"><a href="#强化学习-Reinforcement-Learning" class="headerlink" title="强化学习(Reinforcement Learning)"></a>强化学习(Reinforcement Learning)</h2><p>是指智能系统在与环境的连续互动中学习最优行为策略的机器学习问题，智能系统从环境中观测到一个状态和一个奖励，依此来采取一个动作，环境根据智能系统选择的动作，决定下一步t+1的状态和奖励，智能系统的目标不是<strong>短期奖励</strong>的最大化，而是<strong>长期累积奖励</strong>的最大化</p><ul><li>假设智能系统与环境的互动是基于马尔可夫决策过程，智能系统能观测到的是与环境互动得到的数据序列，强化学习的本质是学习<strong>最优的决策</strong></li></ul><h3 id="马尔可夫决策过程具有马尔可夫性："><a href="#马尔可夫决策过程具有马尔可夫性：" class="headerlink" title="马尔可夫决策过程具有马尔可夫性："></a><strong>马尔可夫决策过程具有马尔可夫性：</strong></h3><ul><li><p>下一个状态只依赖于前一个状态与动作，由状态转移概率函数表示P(s’|s,a)</p></li><li><p>下一个奖励依赖于前一个状态与动作，由奖励函数r(s,a)   ( <strong>r(s,a) = E(r’|s,a)</strong> )</p></li></ul><h3 id="强化学习的马尔可夫决策过程"><a href="#强化学习的马尔可夫决策过程" class="headerlink" title="强化学习的马尔可夫决策过程"></a>强化学习的马尔可夫决策过程</h3><p>———-<strong>是状态、奖励、动作序列上的随机过程</strong></p><p><strong>策略π</strong>定义为<strong>给定状态下</strong>动作的函数a=f(s)或者条件概率分布P(a|s)</p><p><strong>价值函数</strong>定义为策略π从<strong>某一状态s</strong>开始的长期累积奖励的数学期望</p><p><img src="https://cdn.jsdelivr.net/gh/MatthewAden/blog.img/uTools_1642949993984.png" style="zoom:50%;" />(γ是衰减系数，为0到1)</p><p><strong>动作价值函数</strong>定义为策略π从<strong>某一状态s</strong>和<strong>动作a</strong>开始的长期累积奖励的数学期望</p><p>强化学习的<strong>目标</strong>就是在所有可能的策略中选出<strong>价值函数最大</strong>的策略</p><h3 id="强化学习的方法包括："><a href="#强化学习的方法包括：" class="headerlink" title="强化学习的方法包括："></a>强化学习的<strong>方法</strong>包括：</h3><ul><li>基于策略(无模型方法)</li><li>基于价值(无模型方法)</li><li>模型方法</li></ul><h2 id="半监督学习与主动学习"><a href="#半监督学习与主动学习" class="headerlink" title="半监督学习与主动学习"></a>半监督学习与主动学习</h2><p>概念：半监督学习是利用标注数据与未标注数据学习预测模型的机器学习问题</p><pre><code> 主动学习是指机器不断主动给出实例让教师进行标注，然后利用标注数据进行学习预测模型的机器学习问题</code></pre>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
          <category> 李航统计学习方法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习回顾篇--sklearn</title>
      <link href="/2022/01/19/1.20/"/>
      <url>/2022/01/19/1.20/</url>
      
        <content type="html"><![CDATA[<h2 id="调包、加载处理后的数据"><a href="#调包、加载处理后的数据" class="headerlink" title="调包、加载处理后的数据"></a>调包、加载处理后的数据</h2><pre class="language-python" data-language="python"><code class="language-python"># 调包、加载处理后的数据import pandas as pdimport numpy as npimport matplotlib.pyplot as pltimport seaborn as snsfrom IPython.display import Image%matplotlib inlineplt.rcParams[&#39;font.sans-serif&#39;] &#x3D; [&#39;SimHei&#39;]  # 用来正常显示中文标签plt.rcParams[&#39;axes.unicode_minus&#39;] &#x3D; False  # 用来正常显示负号plt.rcParams[&#39;figure.figsize&#39;] &#x3D; (10, 6)  # 设置输出图片大小data_1 &#x3D; pd.read_csv(&#39;train.csv&#39;)data_2 &#x3D; pd.read_csv(&#39;clear_data.csv&#39;)</code></pre><h2 id="模型搭建"><a href="#模型搭建" class="headerlink" title="模型搭建"></a>模型搭建</h2><ul><li>处理完前面的数据我们就得到建模数据，下一步是选择合适模型</li><li>在进行模型选择之前我们需要先知道数据集最终是进行<strong>监督学习</strong>还是<strong>无监督学习</strong></li><li>模型的选择一方面是通过我们的任务来决定的。</li><li>除了根据我们任务来选择模型外，还可以根据数据样本量以及特征的稀疏性来决定</li><li>刚开始我们总是先尝试使用一个基本的模型来作为其baseline，进而再训练其他模型做对比，最终选择泛化能力或性能比较好的模型</li></ul><p><img src="https://cdn.jsdelivr.net/gh/MatthewAden/blog.img/201901242333546.png" alt="算法路径选择图"></p><h3 id="切割训练集和测试集"><a href="#切割训练集和测试集" class="headerlink" title="切割训练集和测试集"></a>切割训练集和测试集</h3><p>这里使用留出法划分数据集</p><ul><li>将数据集分为自变量和因变量</li><li>按比例切割训练集和测试集(一般测试集的比例有30%、25%、20%、15%和10%)</li><li>使用分层抽样</li><li>设置随机种子以便结果能复现</li><li>切割数据集是为了后续能评估模型泛化能力</li><li>sklearn中切割数据集的方法为<code>train_test_split</code></li><li>查看函数文档可以在jupyter noteboo里面使用<code>train_test_split?</code>后回车即可看到</li><li>分层和随机种子在参数里寻找</li></ul><h4 id="分层抽样的概念"><a href="#分层抽样的概念" class="headerlink" title="分层抽样的概念"></a>分层抽样的概念</h4><p>抽样时，将总体分成互不交叉的层，然后按照一定的比例，从各层独立地抽取一定数量的个体，将各层取出的个体合在一起作为样本，这种抽样方法叫分层抽样。</p><p>有几个关键要点</p><ul><li>总体个体差异明显，每层的差异比较大，层内个体间的差异比较小</li><li><strong>每层可以抽取多少样本</strong>，常见的有以下这些方案</li><li>如果根据它在总体中占的比例来抽取，就是等比例抽样</li><li><strong>也可以对不同的层赋予不同的权重，手动控制各层的抽样规模。</strong></li><li>对每一层都分配同样的个体数</li><li>各层抽得的样本数与所抽得的总样本数之比等于该层方差与各类方差之和的比</li><li>每层抽取样本时，采用简单随机抽样</li></ul><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ol><li>如果层内的具有较低的标准偏差（与总体中的总体标准偏差相比），则分层会产生较小的估计误差。</li><li>对于许多应用，当人口被分组到层中时，测量变得更易于管理。</li><li>分层抽样特别适用于<strong>既要对总体参数进行推断</strong>，<strong>也要对各子总体(层)的参数进行推断</strong>的情形</li></ol><pre class="language-python" data-language="python"><code class="language-python">from sklearn.model_selection import train_test_splitx &#x3D; data_2y &#x3D; data_1[&#39;Survived&#39;]# 对数据集进行切割,stratify&#x3D;y是保证测试集与训练集的数据分类比例与y一致，例如y中男女比例是2比1，则取出的测试集与训练集的数据男女比例也是2比1X_train, X_test, y_train, y_test &#x3D; train_test_split(x,y,stratify&#x3D;y,random_state&#x3D;0)</code></pre><h3 id="模型创建"><a href="#模型创建" class="headerlink" title="模型创建"></a>模型创建</h3><ul><li>创建基于线性模型的分类模型（逻辑回归）</li><li>创建基于树的分类模型（决策树、随机森林）</li><li>分别使用这些模型进行训练，分别的到训练集和测试集的得分</li><li><p>查看模型的参数，并更改参数值，观察模型变化</p></li><li><p>逻辑回归不是回归模型而是分类模型，不要与<code>LinearRegression</code>混淆</p></li><li>随机森林其实是决策树集成为了降低决策树过拟合的情况</li><li>线性模型所在的模块为<code>sklearn.linear_model</code></li><li>树模型所在的模块为<code>sklearn.ensemble</code></li></ul><pre class="language-python" data-language="python"><code class="language-python">from sklearn.linear_model import LogisticRegressionfrom sklearn.ensemble import RandomForestClassifier#默认参数的逻辑回归lr &#x3D; LogisticRegression()lr.fit(X_train, y_train)# 查看训练集和测试集score值print(&quot;Training set score: &#123;:.2f&#125;&quot;.format(lr.score(X_train, y_train)))print(&quot;Testing set score: &#123;:.2f&#125;&quot;.format(lr.score(X_test, y_test)))# 调整参数后的逻辑回归模型lr2 &#x3D; LogisticRegression(C&#x3D;100)lr2.fit(X_train, y_train)print(&quot;Training set score: &#123;:.2f&#125;&quot;.format(lr2.score(X_train, y_train)))print(&quot;Testing set score: &#123;:.2f&#125;&quot;.format(lr2.score(X_test, y_test)))# 默认参数的随机森林分类模型rfc &#x3D; RandomForestClassifier()rfc.fit(X_train, y_train)print(&quot;Training set score: &#123;:.2f&#125;&quot;.format(rfc.score(X_train, y_train)))print(&quot;Testing set score: &#123;:.2f&#125;&quot;.format(rfc.score(X_test, y_test)))# 调整参数后的随机森林分类模型rfc2 &#x3D; RandomForestClassifier(n_estimators&#x3D;100, max_depth&#x3D;5)rfc2.fit(X_train, y_train)print(&quot;Training set score: &#123;:.2f&#125;&quot;.format(rfc2.score(X_train, y_train)))print(&quot;Testing set score: &#123;:.2f&#125;&quot;.format(rfc2.score(X_test, y_test)))</code></pre><h3 id="输出模型预测结果"><a href="#输出模型预测结果" class="headerlink" title="输出模型预测结果"></a>输出模型预测结果</h3><ul><li>输出模型预测分类标签</li><li><p>输出不同分类标签的预测概率</p></li><li><p>一般监督模型在sklearn里面有个<code>predict</code>能输出预测标签，<code>predict_proba</code>则可以输出标签概率</p></li></ul><pre class="language-python" data-language="python"><code class="language-python">pred &#x3D; lr.predict(X_train)# 此时我们可以看到0和1的数组pred[:10]# 预测标签概率pred_proba &#x3D; lr.predict_proba(X_train)pred_proba[:10]</code></pre>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>研后Python复习回顾--数据分析篇</title>
      <link href="/2022/01/13/1.13/"/>
      <url>/2022/01/13/1.13/</url>
      
        <content type="html"><![CDATA[<h2 id="drop函数基本介绍"><a href="#drop函数基本介绍" class="headerlink" title="drop函数基本介绍"></a>drop函数基本介绍</h2><ul><li>用于删除数据集中多余的数据</li></ul><pre class="language-python" data-language="python"><code class="language-python">DataFrame.drop(labels&#x3D;None, axis&#x3D;0, index&#x3D;None, columns&#x3D;None, inplace&#x3D;False)</code></pre><p><strong>labels</strong>:待删除的行名or列名；<br><strong>axis</strong>:删除时所参考的轴，0为行，1为列；<br><strong>index</strong>:待删除的行名<br><strong>columns</strong>:待删除的列名<br><strong>inplace</strong>:布尔值，默认为False,这是返回的是一个copy;若为True,返回的是删除相应数据后的版本 </p><h2 id="lambda函数"><a href="#lambda函数" class="headerlink" title="lambda函数"></a>lambda函数</h2><ul><li>lambda 函数是一种小的匿名函数，lambda 函数可接受任意数量的参数，但只能有一个表达式。</li></ul><pre class="language-python" data-language="python"><code class="language-python">#例1# 语法lambda arguments : expressionx &#x3D; lambda a, b, c : a + b + cprint(x(5, 6, 2))#例2def myfunc(n):  return lambda a : a * nmydoubler &#x3D; myfunc(2)print(mydoubler(11))</code></pre><h2 id="map函数"><a href="#map函数" class="headerlink" title="map函数"></a>map函数</h2><ul><li>map是python内置函数，会根据提供的函数对指定的序列做映射，map()函数的格式是</li></ul><pre class="language-python" data-language="python"><code class="language-python">map(function,iterable,...)    def square(x) :                            #计算平方数        return x ** 2map(square, [1,2,3,4,5])                       #计算列表各个元素的平方&lt;map object at 0x100d3d550&gt;                    #返回迭代器list(map(square, [1,2,3,4,5]))                 #使用list() 转换为列表&gt;&gt;&gt;[1, 4, 9, 16, 25]list(map(lambda x: x ** 2, [1, 2, 3, 4, 5]))   # 使用 lambda 匿名函数&gt;&gt;&gt;[1, 4, 9, 16, 25]#map()还能进行类型转换list(map(int, (1, 2, 3)))&gt;&gt;&gt;[1, 2, 3]#可以提取字典中的keylist(map(int,&#123;&#39;1&#39;:2,&#39;2&#39;:3,&#39;3&#39;:4&#125;))&gt;&gt;&gt;[1, 2, 3]</code></pre><h2 id="重置索引列"><a href="#重置索引列" class="headerlink" title="重置索引列"></a>重置索引列</h2><pre class="language-python" data-language="python"><code class="language-python">df.reset_index(drop&#x3D;True) #将索引index列重置，drop&#x3D;true是避免将旧索引添加为列</code></pre><h2 id="利用loc、iloc提取行列数据"><a href="#利用loc、iloc提取行列数据" class="headerlink" title="利用loc、iloc提取行列数据"></a>利用loc、iloc提取行列数据</h2><pre class="language-python" data-language="python"><code class="language-python">data.loc[&#39;a&#39;]   #取索引为a的行data.loc[:,[&#39;a&#39;]]  #取‘a’列data.loc[[&#39;a&#39;,&#39;b&#39;],[&#39;A&#39;,&#39;B&#39;]] #取a,b行与A,B列的相交数data.loc[:,:] #取所有数据iloc基本语法类似 只是需指定第几行第几列data.iloc[[0]] #取第一行</code></pre><h2 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h2><p>1.<strong>Series排序</strong></p><ul><li>Series.sort_index 索引排序</li><li>Series.sort_values 值引排序</li></ul><p>2.<strong>DataFrame排序</strong></p><ul><li>DataFrame<strong>.</strong>sort_index  索引排序</li><li>DataFrame<strong>.</strong>sort_values 值引排序</li></ul><pre class="language-python" data-language="python"><code class="language-python">df &#x3D; pd.DataFrame(np.arange(8).reshape((2, 4)),index &#x3D; [3,2],columns &#x3D; [&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;])df.sort_index()                             #index按照列索引升序排列df.sort_index(axis &#x3D; 1)                     #让列索引升序排序df.sort_index(axis &#x3D; 1,ascending &#x3D; False)   #让列索引降序排序#让任选a,b两列数据同时降序排列df.sort_values(by &#x3D;[&#39;a&#39;,&#39;b&#39;],ascending &#x3D; [False,False])</code></pre><h2 id="数据清洗及特征处理"><a href="#数据清洗及特征处理" class="headerlink" title="数据清洗及特征处理"></a>数据清洗及特征处理</h2><h3 id="1-处理空缺值"><a href="#1-处理空缺值" class="headerlink" title="1.处理空缺值"></a>1.处理空缺值</h3><h4 id="1-1-dropna函数"><a href="#1-1-dropna函数" class="headerlink" title="1.1.dropna函数"></a>1.1.dropna函数</h4><ul><li>用来移除空缺值</li></ul><pre class="language-python" data-language="python"><code class="language-python">DataFrame.dropna(axis&#x3D;0, how&#x3D;&#39;any&#39;, thresh&#x3D;None, subset&#x3D;None,inplace&#x3D;False)df.dropna()                 #只保留行列都没有空值的df.dropna(axis&#x3D;&#39;columns&#39;)   #只保持某行中没有空值的df.dropna(how&#x3D;&#39;all&#39;)        #只去除所有元素缺失的df.dropna(thresh&#x3D;2)         #默认去除某行有两个缺失的，更改axis可以变成列df.dropna(subset&#x3D;[&#39;name&#39;, &#39;toy&#39;]) #指定两列去除缺失</code></pre><h4 id="1-2-fillna函数"><a href="#1-2-fillna函数" class="headerlink" title="1.2.fillna函数"></a>1.2.fillna函数</h4><ul><li>填充空缺值</li></ul><pre class="language-python" data-language="python"><code class="language-python">DataFrame.fillna(value&#x3D;None,method&#x3D;None,axis&#x3D;None,inplace&#x3D;False,limit&#x3D;None,downcast&#x3D;None)df.fillna(0) #用0填充空缺值#A列用0填充values &#x3D; &#123;&quot;A&quot;: 0, &quot;B&quot;: 1, &quot;C&quot;: 2, &quot;D&quot;: 3&#125;df.fillna(value&#x3D;values)</code></pre><h3 id="2-处理重复值"><a href="#2-处理重复值" class="headerlink" title="2.处理重复值"></a>2.处理重复值</h3><pre class="language-python" data-language="python"><code class="language-python">df[df.duplicated()]       #查看重复数据df &#x3D; df.drop_duplicates() #清除重复数据</code></pre><h2 id="特征观察与处理"><a href="#特征观察与处理" class="headerlink" title="特征观察与处理"></a>特征观察与处理</h2><h3 id="1-将连续变量进行离散化处理"><a href="#1-将连续变量进行离散化处理" class="headerlink" title="1.将连续变量进行离散化处理"></a>1.将连续变量进行离散化处理</h3><pre class="language-python" data-language="python"><code class="language-python">#将连续变量Age平均分箱成5个年龄段，并分别用类别变量12345表示df[&#39;AgeBand&#39;] &#x3D; pd.cut(df[&#39;Age&#39;], 5,labels &#x3D; [1,2,3,4,5])#将连续变量Age划分为(0,5] (5,15] (15,30] (30,50] (50,80]五个年龄段，并分别用类别变量12345表示df[&#39;AgeBand&#39;] &#x3D; pd.cut(df[&#39;Age&#39;],[0,5,15,30,50,80],labels &#x3D; [1,2,3,4,5])#将连续变量Age按10% 30% 50 70% 90%五个年龄段，并用分类变量12345表示df[&#39;AgeBand&#39;] &#x3D; pd.cut(df[&#39;Age&#39;],[0,0.1,0.3,0.5,0.7,0.9],labels &#x3D; [1,2,3,4,5])</code></pre><h3 id="2-对文本变量进行转换"><a href="#2-对文本变量进行转换" class="headerlink" title="2.对文本变量进行转换"></a>2.对文本变量进行转换</h3><pre class="language-python" data-language="python"><code class="language-python">#查看类别文本变量名及种类df[&#39;Sex&#39;].value_counts()#将类别文本转换为12345,此处是把性别用1,2来量化df[&#39;Sex_num&#39;] &#x3D; df[&#39;Sex&#39;].replace([&#39;male&#39;,&#39;female&#39;],[1,2])df[&#39;Sex_num&#39;] &#x3D; df[&#39;Sex&#39;].map(&#123;&#39;male&#39;: 1, &#39;female&#39;: 2&#125;)</code></pre>]]></content>
      
      
      <categories>
          
          <category> Python知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>研后Python复习回顾--数据分析篇</title>
      <link href="/2022/01/11/1.12/"/>
      <url>/2022/01/11/1.12/</url>
      
        <content type="html"><![CDATA[<h2 id="数据导入"><a href="#数据导入" class="headerlink" title="数据导入"></a>数据导入</h2><ul><li><p>绝对路径就是文件的真正存在的路径，是指从硬盘的根目录(盘符)开始，进行一级级目录指向文件。</p></li><li><p>相对路径就是以当前文件为基准进行一级级目录指向被引用的资源文件。</p></li><li><p>Pandas能从文本文件和Excel文件中读入数据，形成dataframe，也可以将dataframe导出到文本文件、Excel文件中存储起来。</p></li><li><p>导入函数有(1)pd.read_csv()：导入后缀名为.csv,txt的文本文件, (2)pd.read_excel()：导入后缀名为.xlsx的Excel文件</p></li><li><p>导出函数有(1)df.to_csv)()：将数据存储到csv文件或txt文件中, (2)df.to_excel()：将数据存储到Excel文件中</p></li><li><p>无论是导入函数还是导出函数，都有参数 header，表示 dataframe 的列索引。而行索引在导入函数中用参数 index_col 表示，将某列指定为行索引；行索引在导出函数中用参数 index 表示，指示是否要存好行索引。</p><h3 id="1-导入文件"><a href="#1-导入文件" class="headerlink" title="1.导入文件"></a>1.导入文件</h3><ul><li>导入文本文件：pd.read_csv()</li></ul><p>pd.read_csv()函数不仅可以导入csv文件，也可以导入txt文件。</p><pre class="language-python" data-language="python"><code class="language-python"># 导入test.csv文件df &#x3D; pd.read_csv(&#39;test.csv&#39;)# 导入test.txt文件df &#x3D; pd.read_csv(&#39;test.txt&#39;)</code></pre><ul><li>指定分隔符</li></ul><p>文本文件中，用分隔符来分隔每个值，所以读入的时候，要用参数sep告诉函数分隔符是什么，默认的分隔符是逗号。</p><pre class="language-python" data-language="python"><code class="language-python">df &#x3D; pd.read_csv(&#39;test.csv&#39;,sep&#x3D;&#39;.&#39;)  #指定分隔符是点号   </code></pre><ul><li>指定读入excel的sheet页</li></ul><p>Excel文件在读入时，默认读取第一页。但如果Excel文件有多页，且不想读取第一页而是其他页，则要用参数sheetname传入读入页的名称。</p><pre class="language-python" data-language="python"><code class="language-python">df &#x3D; pd.read_excel(&#39;test.xlsx&#39;)        #导入test.xlsx文件# 导入test.xlsx文件的sheet1页df &#x3D; pd.read_excel(&#39;test.xlsx&#39;, sheetname&#x3D;&#39;sheet1&#39;)</code></pre><h3 id="2-相对路径和绝对路径"><a href="#2-相对路径和绝对路径" class="headerlink" title="2.相对路径和绝对路径"></a>2.相对路径和绝对路径</h3><p>导入文件时，要指定文件所在的路径，可以是相对路径，也可以是绝对路径。</p><pre class="language-python" data-language="python"><code class="language-python"># 导入windows下的绝对路径：导入E盘下的test.csvpd.read_csv(&#39;E:\test.csv&#39;)# 导入mac下的绝对路径：导入xxx文件夹下的test.csvpd.read_csv(&#39;&#x2F;Users&#x2F;xxx&#x2F;test.csv&#39;)</code></pre><p>相对路径指的是当前的py文件所在的路径。当要导入的文件和py文件在同一个文件夹下，则可以用相对路径导入。</p><pre class="language-python" data-language="python"><code class="language-python">pd.read_csv(&#39;test.csv&#39;)</code></pre><p><strong>路径的转义</strong></p><pre class="language-python" data-language="python"><code class="language-python">Location &#x3D; r&#39;.&#x2F;test.csv&#39; df &#x3D; pd.read_csv(Location)</code></pre><p>注意，因为斜线是一个特殊字符，在字符串之前放置前导的 r，将会把整个字符串不进行转义。</p><h3 id="3-读取指定的列"><a href="#3-读取指定的列" class="headerlink" title="3.读取指定的列"></a>3.读取指定的列</h3><p>有时候，我们并不想把所有的列都读入，只想读取前几列，或后几列，或指定几列。这时，可以使用usecols参数。</p><pre class="language-python" data-language="python"><code class="language-python"># 读取csv数据中的第0列，第1列，第2列。df &#x3D; pd.read_csv(&#39;test.csv&#39;, usecols&#x3D;[0,1,2])</code></pre><h3 id="4-行列索引"><a href="#4-行列索引" class="headerlink" title="4.行列索引"></a>4.行列索引</h3><ul><li>默认列索引和行索引</li></ul><p>导入文件时，若不指定列索引，则默认将文件中的第一行当成dataframe列索引，并且为数据自动添加整数行索引。</p><pre class="language-python" data-language="python"><code class="language-python"># 默认将test.csv中的第一行当为列索引，自动添加从0开始的整数索引pd.read_csv(&#39;test.csv&#39;)</code></pre><ul><li>第一行非列索引</li></ul><p>若导入时，第一行是数据，并非列标题，可以将参数header设置为None，即不让第一行成为列索引。但系统会自动添加从0开始的列索引。</p><pre class="language-python" data-language="python"><code class="language-python">df &#x3D; pd.read_csv(&#39;test.csv&#39;, header&#x3D;None)</code></pre><ul><li>指定某行为列索引</li></ul><p>导入数据时默认第一行为列索引，但如果数据中第一行并非标题，而是第k行，则可以用参数header指定第k行为列索引。</p><pre class="language-python" data-language="python"><code class="language-python"># 指定test.csv中的第3行是列索引df &#x3D; pd.read_csv(&#39;test.csv&#39;, header&#x3D;3)</code></pre><ul><li>添加列索引</li></ul><p>若导入的数据中并没有任何一行能当列索引，可以用参数 names 自定义列索引。</p><pre class="language-python" data-language="python"><code class="language-python"># 指定test.csv（只有两列）中的列索引为[&#39;column1&#39;,&#39;column2&#39;]df &#x3D; pd.read_csv(&#39;test.csv&#39;, names&#x3D;[&#39;column1&#39;,&#39;column2&#39;])</code></pre><ul><li>指定行索引</li></ul><p>导入数据时，会自动添加从0开始的整数行索引。若需要指定数据中第K列为行索引，则要用index_col参数。</p><pre class="language-python" data-language="python"><code class="language-python"># 指定第0列是dataframe的行索引df&#x3D;pd.read_csv(&#39;test.csv&#39;,index_col&#x3D;0)# 指定列名为&#39;column&#39;的列是dataframe的行索引df&#x3D;pd.read_csv(&#39;test.csv&#39;,index_col&#x3D;&#39;column&#39;)</code></pre></li></ul><h2 id="导出数据"><a href="#导出数据" class="headerlink" title="导出数据"></a>导出数据</h2><h3 id="1-写入文本文件：df-to-csv"><a href="#1-写入文本文件：df-to-csv" class="headerlink" title="1.写入文本文件：df.to_csv()"></a>1.写入文本文件：df.to_csv()</h3><p>  pandas可将dataframe存储到csv文件或txt文件中。存储的路径可以是绝对路径，也可以是相对路径。</p>  <pre class="language-python" data-language="python"><code class="language-python"># 将数据表df存入当前py文件所在位置下的test.csv文件中，如果没有这个文件，会自动创建df.to_csv(&#39;test.csv&#39;)# 将数据表df存入当前py文件所在位置下的test.txt文件中，如果没有这个文件，会自动创建df.to_csv(&#39;test.txt&#39;)</code></pre><h3 id="2-写入excel文件：df-to-excel"><a href="#2-写入excel文件：df-to-excel" class="headerlink" title="2.写入excel文件：df.to_excel()"></a>2.写入excel文件：df.to_excel()</h3><p>  写入Excel文件时，默认会写入Excel文件中的第一页。</p>  <pre class="language-python" data-language="python"><code class="language-python"># 将数据表df写入test.xlsx文件中df.to_excel(&#39;test.xlsx&#39;)</code></pre><p>  如果想要写入指定的页，则用参数sheet_name。</p>  <pre class="language-python" data-language="python"><code class="language-python"># 将数据表df写入test.xlsx文件中&#39;Sheet1&#39;页df.to_excel(&#39;test.xlsx&#39;,sheet_name&#x3D;&#39;Sheet1&#39;)</code></pre><h3 id="3-行列索引"><a href="#3-行列索引" class="headerlink" title="3.行列索引"></a>3.行列索引</h3><ul><li><p>存储行索引</p><p>存储时，默认将数据表中的行索引也存储到文件中。</p><pre class="language-python" data-language="python"><code class="language-python"># test.csv的行索引将会被存储起来df.to_csv(&#39;test.csv&#39;)</code></pre></li><li><p>不存储行索引</p><p>导出数据时，默认是要存储行索引的。不存储行索引的话，设置index的值为False。</p><pre class="language-python" data-language="python"><code class="language-python">df.to_csv(&#39;test.csv&#39;, index &#x3D; False)</code></pre></li><li><p>不存储列索引</p><p>导出数据时，默认是要存储列索引的。不存储列索引的话，设置header的值为False。不要列索引，导出的数据就没有列名。</p><pre class="language-python" data-language="python"><code class="language-python">df.to_csv(&#39;test.csv&#39;, header &#x3D; False)</code></pre></li></ul><h2 id="逐块读取文本文件"><a href="#逐块读取文本文件" class="headerlink" title="逐块读取文本文件"></a>逐块读取文本文件</h2><ul><li>在处理很大的文件时，或找出大文件中的参数集以便于后续处理时，你可能只想读取文件的一小部分或逐块对文件进行迭代，如果只想读取几行文件，可以通过nrows参数进行指定即可：</li></ul><pre class="language-python" data-language="python"><code class="language-python">import os  os.getcwd()    #可以查看当前工作目录                                       chunker &#x3D; pd.read_csv(&#39;ch06&#x2F;ex6.csv&#39;, chunksize&#x3D;100，nrows&#x3D;5) #表示只读取5行chunker &#x3D; pd.read_csv(&#39;ch06&#x2F;ex6.csv&#39;, chunksize&#x3D;100) #chunksize表示行数，每100行为一个模块chunker &lt;pandas.io.parsers.TextParser at 0x8398150&gt;   #该数据类型可以让我们对文件进行逐块迭代</code></pre><h2 id="把表头更改成中文"><a href="#把表头更改成中文" class="headerlink" title="把表头更改成中文"></a>把表头更改成中文</h2><pre class="language-py" data-language="py"><code class="language-py">df.columns &#x3D; [&#39;乘客ID&#39;,&#39;是否幸存&#39;,&#39;乘客等级&#39;,&#39;乘客姓名&#39;,&#39;性别&#39;,&#39;年龄&#39;,&#39;堂兄弟&#x2F;妹个数&#39;,&#39;父母与小孩个数&#39;,&#39; 船票信息&#39;,&#39;票价&#39;,&#39;客舱&#39;,&#39;登船港口&#39;]  #直接更改columns</code></pre><h2 id="查看DataFrame数据的基本信息"><a href="#查看DataFrame数据的基本信息" class="headerlink" title="查看DataFrame数据的基本信息"></a>查看DataFrame数据的基本信息</h2><pre class="language-python" data-language="python"><code class="language-python">df.shape——行数 列数df.dtypes——列数据类型df.ndim——数据维度df.index——行索引df.columns——列索引df.values——对象值，二维ndarray数组df.head(10)——显示前10行，默认是5行df.tail()——显示末尾几行，默认是5df.info()——相关系数，如行数，列数，列索引、列非空值个数，列类型，内存占用df.describe()——快速统计结果，计数、均值、标准差、最大值、四分数、最小值df.isnull()——判断数据是否为空，为空的地方返回True，其余地方返回False</code></pre><h2 id="Series-and-DataFrame"><a href="#Series-and-DataFrame" class="headerlink" title="Series and DataFrame"></a>Series and DataFrame</h2><ul><li>Pandas Series 类似表格中的一个列（column），类似于一维数组，可以保存任何数据类型。</li></ul><p>Series 由索引（index）和列组成，函数如下：</p><pre class="language-python" data-language="python"><code class="language-python">pandas.Series( data, index, dtype, name, copy)#例1.通过列表来创建import pandas as pda &#x3D; [&quot;Google&quot;, &quot;Runoob&quot;, &quot;Wiki&quot;]myvar &#x3D; pd.Series(a, index &#x3D; [&quot;x&quot;, &quot;y&quot;, &quot;z&quot;])print(myvar[&quot;y&quot;])      #通过索引读取数据#例2.通过类似字典来创建 此时字典的key变成了索引值import pandas as pdsites &#x3D; &#123;1: &quot;Google&quot;, 2: &quot;Runoob&quot;, 3: &quot;Wiki&quot;&#125;myvar &#x3D; pd.Series(sites, index &#x3D; [1, 2])  #可以指定索引来取其中的一部分print(myvar)</code></pre><ul><li>DataFrame 是一个表格型的数据结构，它含有一组有序的列，每列可以是不同的值类型（数值、字符串、布尔型值）。DataFrame 既有行索引也有列索引，它可以被看做由 Series 组成的字典（共同用一个索引）。</li></ul><pre class="language-python" data-language="python"><code class="language-python">pandas.DataFrame(data, index, columns, dtype, copy)#ndarrays创建--最简单易记的data1 &#x3D; &#123;&quot;报考的学校&quot;:[&#39;东华大学&#39;,&#39;北京大学&#39;,&#39;清华大学&#39;],&quot;想报的学校&quot;:[&quot;北京邮电大学&quot;,&quot;卡内基梅隆&quot;,&#39;Mit&#39;]&#125; school &#x3D; pd.DataFrame(data1,index&#x3D;[&#39;第一梯度&#39;,&#39;第二梯队&#39;,&#39;第三梯队&#39;])  #不能改columns</code></pre>]]></content>
      
      
      <categories>
          
          <category> Python知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>研后Python复习回顾--语法篇(函数篇)</title>
      <link href="/2022/01/08/1.8/"/>
      <url>/2022/01/08/1.8/</url>
      
        <content type="html"><![CDATA[<h2 id="函数的参数"><a href="#函数的参数" class="headerlink" title="函数的参数"></a>函数的参数</h2><h3 id="1-位置参数"><a href="#1-位置参数" class="headerlink" title="1 位置参数"></a>1 位置参数</h3><pre class="language-python" data-language="python"><code class="language-python">def power(x, n):     #此时x,n都是位置参数，调用函数时必须输入两个参数    s &#x3D; 1    while n &gt; 0:        n &#x3D; n - 1        s &#x3D; s * x    return s</code></pre><h3 id="2-默认参数"><a href="#2-默认参数" class="headerlink" title="2 默认参数"></a>2 默认参数</h3><pre class="language-python" data-language="python"><code class="language-python">def power(x, n&#x3D;2):  #n&#x3D;2相当于默认参数 此时我们可以只输入一个参数    s &#x3D; 1    while n &gt; 0:        n &#x3D; n - 1        s &#x3D; s * x    return s</code></pre><ul><li><p><strong>注:当函数有多个参数时，把变化大的参数放前面，变化小的参数放后面，变化小的参数就可以作为默认参数。</strong></p></li><li><p><strong>定义默认参数要牢记一点：默认参数必须指向不变对象！</strong></p></li></ul><pre class="language-python" data-language="python"><code class="language-python">#此时默认参数是列表 是可变参数,Python函数在定义的时候，默认参数L的值就被计算出来了，即[]，因为默认参数L也是一个变量，它指向对象[]，每次调用该函数，如果改变了L的内容，则下次调用时，默认参数的内容就变了，不再是函数定义时的[]了。def add_end(L&#x3D;[]):    L.append(&#39;END&#39;)    return Ladd_end()&gt;&gt;&gt;[&#39;END&#39;]   add_end()&gt;&gt;&gt;[&#39;END&#39;, &#39;END&#39;]#因此我们需要将默认参数改为不变对象 None为不变对象，现在，无论调用多少次，都不会有问题def add_end(L&#x3D;None):    if L is None:        L &#x3D; []    L.append(&#39;END&#39;)    return L</code></pre><h3 id="3-可变参数"><a href="#3-可变参数" class="headerlink" title="3 可变参数"></a>3 可变参数</h3><ul><li>可变参数就是传入的参数个数是可变的，可应用于参数个数不确定</li></ul><pre class="language-python" data-language="python"><code class="language-python"># *+参数名就是可变参数，参数numbers接收到的是一个tuple，调用该函数时，可以传入任意个参数，包括0个参数，此时这些参数会自动转换成一个元组def calc(*numbers):       sum &#x3D; 0    for n in numbers:        sum &#x3D; sum + n * n    return sumcalc(1, 2)&gt;&gt;&gt;5calc()&gt;&gt;&gt; 0</code></pre><p>如果已经有一个list或者tuple，要调用一个可变参数怎么办？可以这样做：</p><pre class="language-python" data-language="python"><code class="language-python">nums &#x3D; [1, 2, 3]calc(nums[0], nums[1], nums[2])14</code></pre><p>这种写法当然是可行的，但有更简单的写法，Python允许在list或tuple前面加一个<code>*</code>号，把list或tuple的元素变成<strong>可变参数</strong>传进去：</p><pre class="language-python" data-language="python"><code class="language-python">#*nums&#96;表示把&#96;nums&#96;这个list的所有元素作为可变参数传进去。nums &#x3D; [1, 2, 3]calc(*nums)14</code></pre><h3 id="4-关键字参数"><a href="#4-关键字参数" class="headerlink" title="4 关键字参数"></a>4 关键字参数</h3><ul><li>关键字参数允许你传入0个或任意个含参数名的参数，这些关键字参数在函数内部自动组装为一个<strong>dict</strong></li><li>类似可变参数 只是由可变参数的tuple变成了dict</li></ul><pre class="language-python" data-language="python"><code class="language-python">def person(name, age, **kw):    print(&#39;name:&#39;, name, &#39;age:&#39;, age, &#39;other:&#39;, kw)person(&#39;Michael&#39;, 30)name: Michael age: 30 other: &#123;&#125;</code></pre><h3 id="5-小结"><a href="#5-小结" class="headerlink" title="5 小结"></a>5 小结</h3><ul><li><p>默认参数一定要用不可变对象，如果是可变对象，程序运行时会有逻辑错误！</p></li><li><p>要注意定义可变参数和关键字参数的语法：</p></li><li><p><code>*args</code>是可变参数，args接收的是一个tuple；</p></li><li><p><code>**kw</code>是关键字参数，kw接收的是一个dict。</p></li><li><p>调用函数时如何传入可变参数和关键字参数的语法：</p></li><li><p>可变参数既可以直接传入：<code>func(1, 2, 3)</code>，又可以先组装list或tuple，再通过<code>*args</code>传入：<code>func(*(1, 2, 3))</code>；</p></li><li><p>关键字参数既可以直接传入：<code>func(a=1, b=2)</code>，又可以先组装dict，再通过<code>**kw</code>传入：<code>func(**&#123;&#39;a&#39;: 1, &#39;b&#39;: 2&#125;)</code>。</p></li><li><p>使用<code>*args</code>和<code>**kw</code>是Python的习惯写法，当然也可以用其他参数名，但最好使用习惯用法。</p></li></ul><h2 id="递归函数"><a href="#递归函数" class="headerlink" title="递归函数"></a>递归函数</h2><ul><li>典型例子 计算1到n的阶乘</li></ul><pre class="language-python" data-language="python"><code class="language-python">#递归计算1到n的阶乘def fac(n):    if n &#x3D;&#x3D; 1:        return n    return n * fac(n-1)    </code></pre><h2 id="切片"><a href="#切片" class="headerlink" title="切片"></a>切片</h2><ul><li><p>L[0:3]表示0开始取，直到索引3为止，但不包括索引3。即索引0，1，2，正好是3个元素。</p></li><li><p>L[-2:]表示从倒数第二个元素开始到最后</p></li><li>L[::5] 所有数，每5个取一个</li><li>tuple也可以用切片操作，只是操作的结果仍是tuple</li><li>字符串也可以用切片操作，只是操作结果仍是字符串</li></ul><h3 id="练习"><a href="#练习" class="headerlink" title="练习"></a>练习</h3><pre class="language-python" data-language="python"><code class="language-python">#利用切片操作，实现一个trim()函数，去除字符串首尾的空格，注意不要调用str的strip()方法：#法1  while循环def trim(s):    while s[:1] &#x3D;&#x3D; &quot; &quot;:        s &#x3D; s[1:]    while s[-1:] &#x3D;&#x3D; &quot; &quot;:        s &#x3D; s[0:-1]    return s #法二 递归def trim(s):    if s[0:1] &#x3D;&#x3D; &quot; &quot;:        return trim(s[1:])    elif s[-1:] &#x3D;&#x3D; &quot; &quot;:        return trim(s[0:-1])    else:        return s        </code></pre>]]></content>
      
      
      <categories>
          
          <category> Python知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>研后C语言复习回顾</title>
      <link href="/2022/01/06/%E7%A0%94%E5%90%8EC%E8%AF%AD%E8%A8%80%E5%A4%8D%E4%B9%A0%E5%9B%9E%E9%A1%BE/"/>
      <url>/2022/01/06/%E7%A0%94%E5%90%8EC%E8%AF%AD%E8%A8%80%E5%A4%8D%E4%B9%A0%E5%9B%9E%E9%A1%BE/</url>
      
        <content type="html"><![CDATA[<h2 id="关系运算"><a href="#关系运算" class="headerlink" title="关系运算"></a>关系运算</h2><ul><li>判断是否相等和不等的优先级比其他关系运算符优先级要低</li><li>关系运算符优先级比算术运算符低 比赋值运算符高</li><li>小tips：  &gt;= 表示的是大于或等于</li></ul><h2 id="判断语句"><a href="#判断语句" class="headerlink" title="判断语句"></a>判断语句</h2><ul><li>if </li><li>if else</li><li>嵌套if语句(可if里嵌套if或if else或if else if else)</li><li>switch语句   （看作是一种基于计算的跳转，计算控制表达式的值后，程序会跳转到相匹配的case,如果执行完分支后，没有遇到break会继续执行下一个分支，这一点尤为要注意）</li><li>switch的控制表达式必须要是整型</li><li>case(常量) 常量也可以是常量表达式 例如1+1</li></ul><h2 id="简单代码练习"><a href="#简单代码练习" class="headerlink" title="简单代码练习"></a>简单代码练习</h2><ul><li>小启示 尽量写单一出口的代码</li></ul><pre class="language-c" data-language="c"><code class="language-c">1.&#x2F;&#x2F; 英尺换算&#x2F;&#x2F; 思路：#include &lt;stdio.h&gt;int main()&#123;    int cm, foot, inch;    scanf(&quot;%d&quot;, &amp;cm);    foot &#x3D; cm &#x2F; 30.48; &#x2F;&#x2F;强制类型转换,会将结果由浮点数转换整数    inch &#x3D; (cm &#x2F; 30.48 - foot) * 12;    printf(&quot;%d %d&quot;, foot, inch);    return 0;&#125;2.&#x2F;&#x2F;然后是几点&#x2F;&#x2F;思路：输入一个时间 首先利用除法和取余得到时和分钟 其次加上流逝的分钟数 最后再用取余和除法转换成终止时间include &lt;stdio.h&gt;int main()&#123;    int begin_time, end_time, time;    scanf(&quot;%d %d&quot;, &amp;begin_time, &amp;time);    end_time &#x3D; begin_time &#x2F; 100 * 60 + begin_time % 100 + time;    printf(&quot;%d%d&quot;, end_time &#x2F; 60, end_time % 60);    return 0;&#125;3.&#x2F;&#x2F; 逆序的三位数且输入数字含有结尾0时输出不应带有前导的0，比如输入700，输出应为7&#x2F;&#x2F; 思路：利用取余、除法运算分离百十个位，同时利用判断语句实现除0要求#include &lt;stdio.h&gt;int main()&#123;    int number, i, j, k;    scanf(&quot;%d&quot;, &amp;number);    i &#x3D; number &#x2F; 100;      &#x2F;&#x2F;百位    j &#x3D; number % 100 &#x2F; 10; &#x2F;&#x2F;十位    k &#x3D; number % 100 % 10; &#x2F;&#x2F;个位    if (k &#x3D;&#x3D; 0 &amp; j &#x3D;&#x3D; 0)    &#123;        printf(&quot;%d&quot;, i);    &#125;    else if (k &#x3D;&#x3D; 0 &amp; j !&#x3D; 0)    &#123;        printf(&quot;%d%d&quot;, j, i);    &#125;    else    &#123;        printf(&quot;%d%d%d&quot;, k, j, i);    &#125;    return 0;&#125;4.&#x2F;&#x2F; 成绩转换#include &lt;stdio.h&gt;int main()&#123;    int score;    scanf(&quot;%d&quot;, &amp;score);    score &#x2F;&#x3D; 10;    switch (score)    &#123;    case 10:      &#x2F;&#x2F; switch执行完一条分支的语句后如不遇到break会继续顺序执行下一个分支    case 9:        printf(&quot;A\n&quot;);        break;    case 8:        printf(&quot;B\n&quot;);        break;    case 7:        printf(&quot;C\n&quot;);        break;    case 6:        printf(&quot;D\n&quot;);        break;    default:        printf(&quot;E\n&quot;);        break;    &#125;    return 0;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> C/C++ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C/C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>vscode远程推送文件至github</title>
      <link href="/2022/01/03/vscode%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E8%87%B3github/"/>
      <url>/2022/01/03/vscode%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E8%87%B3github/</url>
      
        <content type="html"><![CDATA[<p>1.在github上新建一个仓库</p><p>2.在本地用编辑器打开本地的文件夹</p><p>3.此时如需把文件夹中的文件推送至远程仓库，</p><pre class="language-python" data-language="python"><code class="language-python">git init                      #初始化一个本地仓库git add readme.txt            #将这一个文件上传至仓库#git add .                    #将所有文件上传至仓库git commit -m “first commit”  #first commit是备注 即第一次提交git branch -M maingit remote add origin https:&#x2F;&#x2F;github.com&#x2F;xxx&#x2F;xxx.git  #加仓库名git push -u origin main</code></pre><p>4.此时如果修改了文件 vscode左侧源代码管理会出现蓝色圆圈及其数字 表示文件已经更改，我们就需要将这个改变的文件先暂存本地仓库(源代码管理处文件的加号)再提交到本地仓库(<strong>此时会弹出输入框，输入备注回车</strong>) ，最后点击最左下角状态栏的循环箭头即可提交github更新更改</p><p><strong>注:如果非第一次创建只需执行第四步</strong></p>]]></content>
      
      
      <categories>
          
          <category> 编程中遇到的问题 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Markdown</title>
      <link href="/2022/01/02/%E7%AC%AC%E4%B8%80%E4%B8%AA%E5%8D%9A%E5%AE%A2/"/>
      <url>/2022/01/02/%E7%AC%AC%E4%B8%80%E4%B8%AA%E5%8D%9A%E5%AE%A2/</url>
      
        <content type="html"><![CDATA[<h2 id="Markdown语法（typora）"><a href="#Markdown语法（typora）" class="headerlink" title="Markdown语法（typora）"></a>Markdown语法（typora）</h2><h3 id="1-代码块："><a href="#1-代码块：" class="headerlink" title="1.代码块："></a>1.代码块：</h3><ul><li>例</li></ul><pre class="language-python" data-language="python"><code class="language-python">print(&quot;人生苦短，我用python&quot;)  tips:在代码块中并不能进行高亮、加粗等操作</code></pre><h3 id="2-标题"><a href="#2-标题" class="headerlink" title="2.标题"></a>2.标题</h3><ul><li>加内容即生成标题 几个#号则几号标题</li><li>记得#后需加空格</li></ul><h3 id="3-字体"><a href="#3-字体" class="headerlink" title="3.字体"></a>3.字体</h3><h4 id="3-1-加粗"><a href="#3-1-加粗" class="headerlink" title="3.1 加粗"></a>3.1 加粗</h4><h4 id="3-2-高亮"><a href="#3-2-高亮" class="headerlink" title="3.2 高亮"></a>3.2 高亮</h4><h4 id="3-3-删除线"><a href="#3-3-删除线" class="headerlink" title="3.3 删除线"></a>3.3 删除线</h4><h4 id="3-4-斜体"><a href="#3-4-斜体" class="headerlink" title="3.4 斜体"></a>3.4 斜体</h4><h3 id="4-引用"><a href="#4-引用" class="headerlink" title="4.引用"></a>4.引用</h3><ul><li>用快捷键即可</li></ul><h3 id="5-分割线"><a href="#5-分割线" class="headerlink" title="5.分割线"></a>5.分割线</h3><hr><h3 id="6-图片插入"><a href="#6-图片插入" class="headerlink" title="6.图片插入"></a>6.图片插入</h3><p><img src="https://images.unsplash.com/photo-1457305237443-44c3d5a30b89?ixlib=rb-1.2.1&amp;ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&amp;auto=format&amp;fit=crop&amp;w=2074&amp;q=80" alt="图片"></p><h3 id="7-超链接"><a href="#7-超链接" class="headerlink" title="7.超链接"></a>7.超链接</h3><p><a href="www.baidu.com"></a></p><h3 id="8-列表"><a href="#8-列表" class="headerlink" title="8.列表"></a>8.列表</h3><ul><li>无序列表</li></ul><p>1.有序列表</p>]]></content>
      
      
      <categories>
          
          <category> 实用工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Markdown </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
